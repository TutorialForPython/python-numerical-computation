{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流处理\n",
    "\n",
    "dask的实时任务提交接口非常适合做流处理,通过结合[streamz](https://github.com/python-streamz/streamz)我们可以构造复杂的流处理系统.\n",
    "\n",
    "\n",
    "流处理常用于处理数据流,构造数据处理管道.具体的内容我们后面数据科学部分再说."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用streamz做流处理\n",
    "\n",
    "streamz的基本接口主要有如下几类:\n",
    "\n",
    "###  基本的的流处理结构\n",
    "\n",
    "+ `map(upstream, func, *args, **kwargs)`用于将流中的每个数据分发给处理函数;\n",
    "+ `Stream.emit(self, x[, asynchronous])`用于将数据提交到流;\n",
    "+ `sink(upstream, func, *args, **kwargs)`则将函数应用于每个结果.\n",
    "\n",
    "一个最简单最基本的流处理单元如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "5\n",
      "10\n",
      "17\n",
      "26\n",
      "37\n",
      "50\n",
      "65\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "from streamz import Stream\n",
    "\n",
    "def increment(x):\n",
    "    return x**2 + 1\n",
    "\n",
    "source = Stream()\n",
    "source.map(increment).sink(print)\n",
    "\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置缓冲区防止流堵塞\n",
    "\n",
    "由于机器的性能或者短时间内大量数据的涌入,流处理可能会堵塞,我们可以使用`buffer(upstream, n, **kwargs)`来设置一个缓冲区,以应付这种情况.在上一个节点未能处理完之前如果有新的节点进来,那么它会被放在缓冲区."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "5\n",
      "10\n",
      "17\n",
      "26\n",
      "37\n",
      "50\n",
      "65\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "from streamz import Stream\n",
    "\n",
    "def increment(x):\n",
    "    return x**2 + 1\n",
    "\n",
    "source = Stream()\n",
    "source.buffer(100).map(increment).sink(print)\n",
    "\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 积累状态\n",
    "\n",
    "使用接口`accumulate(upstream, func[, start, …])`可以积累流中的状态,类似`reduce`操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "8\n",
      "18\n",
      "35\n",
      "61\n",
      "98\n",
      "148\n",
      "213\n",
      "295\n"
     ]
    }
   ],
   "source": [
    "from streamz import Stream\n",
    "\n",
    "def increment(x):\n",
    "    return x**2 + 1\n",
    "\n",
    "def add(x,y):\n",
    "    return x+y\n",
    "\n",
    "source = Stream()\n",
    "source.map(increment).accumulate(add).sink(print)\n",
    "\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 操作流中元素\n",
    "\n",
    "+ 确保唯一性\n",
    "\n",
    "可以使用`unique(upstream[, maxsize, key, hashable])`保证流中元素唯一性,这个接口可以设置`maxsize`参数 用于控制这个唯一性的范围(最近多少条没有重复),重复的元素则会被过滤掉;而参数`key`和python中其他itertools一样用于确定不重复的键如何取到."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "##################\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "source = Stream()\n",
    "#source.unique(maxsize=1).sink(print)\n",
    "source.unique(maxsize=4).sink(print)\n",
    "for i in [1,2,3,2,3,2,2,4,5,6]:\n",
    "    source.emit(i)\n",
    "print(\"##################\")\n",
    "source = Stream()\n",
    "source.unique(maxsize=1).sink(print)\n",
    "for i in [1,2,3,2,3,2,2,4,5,6]:\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 过滤元素\n",
    "\n",
    "可以使用`filter(upstream, predicate, *args, **kwargs)`来主动过滤一些符合条件的元素."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "source = Stream()\n",
    "source.filter(lambda x: x%2 == 0).sink(print)\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 将流数据压扁\n",
    "\n",
    "类似spark中的flatten,`flatten()`也是一个功能,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "source = Stream()\n",
    "\n",
    "source.flatten().sink(print)\n",
    "\n",
    "for i in [[1, 2, 3], [4, 5], [6, 7, 7]]:\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 延迟处理\n",
    "\n",
    "借助事件循环,我们可以使用`delay(upstream, interval, **kwargs)`接口来推迟执行的时间."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "source = Stream()\n",
    "source.delay(1).filter(lambda x: x%2 == 0).sink(print)\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 固定时间间隔执行\n",
    "\n",
    "`rate_limit(upstream, interval, **kwargs)`可以实现这个功能,它可以用于平稳流的执行."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "source = Stream()\n",
    "source.rate_limit(interval=1).sink(print)\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 截断缓存流\n",
    "\n",
    "流处理一个很重要的功能就是计算序列中元素附近的一些统计量,这种时候截断与缓存就相当有用了."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 每隔一定数量截断流构建元素\n",
    "\n",
    "`partition(upstream, n, **kwargs)` 可以实现这个功能,不过一旦停止,多出来的元素会被抛弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2)\n",
      "(3, 4, 5)\n",
      "(6, 7, 8)\n"
     ]
    }
   ],
   "source": [
    "source = Stream()\n",
    "source.partition(n=3).sink(print)\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 将元素保存在缓存中\n",
    "\n",
    "`streamz.collect(upstream, cache=None, **kwargs)`可以将流中的元素保存到缓存中,并在调用对象的`flush`时将它们作为集合发出并清空缓存."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n"
     ]
    }
   ],
   "source": [
    "source1 = Stream()\n",
    "source2 = Stream()\n",
    "collector = source1.collect()\n",
    "collector.sink(print)\n",
    "source2.sink(collector.flush)\n",
    "for i in range(10):\n",
    "    source1.emit(i)\n",
    "source2.emit('anything')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以设置`cache`参数,通常我们使用一个deque来限定缓存长度.外部定义的缓存也可以在流处理外部使用,这通常用于保存近期数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "(5, 6, 7, 8, 9)\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "cache = deque([],5)\n",
    "source1 = Stream()\n",
    "source2 = Stream()\n",
    "collector = source1.collect(cache=cache)\n",
    "collector.sink(print)\n",
    "source2.sink(collector.flush)\n",
    "for i in range(10):\n",
    "    source1.emit(i)\n",
    "    print(len(cache))\n",
    "source2.emit('anything')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 按元素个数窗口截断并缓存元素\n",
    "\n",
    "`sliding_window(upstream, n, return_partial=True, **kwargs)`可以实现这个功能,它会保存当前元素和最近的(n-1)个元素组成tuple构成一个新的元素,参数`return_partial=True`意味着在流开始时,元素前面元素不足够的情况下也会被构成tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0, 1)\n",
      "(0, 1, 2)\n",
      "(1, 2, 3)\n",
      "(2, 3, 4)\n",
      "(3, 4, 5)\n",
      "(4, 5, 6)\n",
      "(5, 6, 7)\n",
      "(6, 7, 8)\n",
      "(7, 8, 9)\n"
     ]
    }
   ],
   "source": [
    "source = Stream()\n",
    "source.sliding_window( n=3, return_partial=True).sink(print)\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2)\n",
      "(1, 2, 3)\n",
      "(2, 3, 4)\n",
      "(3, 4, 5)\n",
      "(4, 5, 6)\n",
      "(5, 6, 7)\n",
      "(6, 7, 8)\n",
      "(7, 8, 9)\n"
     ]
    }
   ],
   "source": [
    "source = Stream()\n",
    "source.sliding_window( n=3, return_partial=False).sink(print)\n",
    "for i in range(10):\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 按时间窗口截断并缓存元素\n",
    "\n",
    "`timed_window(upstream, interval, **kwargs)`可以实现这个功能.它与上面`sliding_window`不同之处就在于它是按时间截取,注意参数`interval`单位是秒.要注意一旦使用这个接口,它会启动一个事件循环来控制时间."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[0, 1, 2, 3, 4]\n",
      "[5, 6, 7, 8, 9, 10, 11]\n",
      "[12, 13, 14, 15, 16]\n",
      "[17, 18, 19, 20, 21, 22, 23]\n",
      "[24, 25, 26, 27, 28, 29]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "source = Stream()\n",
    "source.timed_window( interval=3).sink(print)\n",
    "for i in range(30):\n",
    "    time.sleep(0.5)\n",
    "    source.emit(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合流\n",
    "\n",
    "python有生成器本身其实已经有一定的流操作能力,那为什么要用`streamz`呢,用它更多的是为了构造复杂的流组合.在业务上流操作也时常需要组合,比如计算一个\n",
    "\n",
    "#### 流分叉\n",
    "\n",
    "我们的source对象可以用于构造流处理的计算图,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tpng'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\LIB\\Anaconda\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\LIB\\Anaconda\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\LIB\\Anaconda\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4d3a246949fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincrement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecrement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrankdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'LR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\LIB\\Anaconda\\lib\\site-packages\\streamz\\core.py\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m         \"\"\"\n\u001b[0;32m    462\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\LIB\\Anaconda\\lib\\site-packages\\streamz\\graph.py\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(node, filename, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         raise RuntimeError(\n",
      "\u001b[1;32m~\\LIB\\Anaconda\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\LIB\\Anaconda\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \"\"\"\n\u001b[0;32m    205\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\LIB\\Anaconda\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tpng'], make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "def increment(x):\n",
    "    return x + 1\n",
    "\n",
    "def decrement(x):\n",
    "    return x - 1\n",
    "\n",
    "source = Stream()\n",
    "a = source.map(increment).sink(print)\n",
    "b = source.map(decrement).sink(print)\n",
    "b.visualize(rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    time.sleep(0.5)\n",
    "    source.emit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 流合并\n",
    "\n",
    "+ `union(*upstreams, **kwargs)`将不同的流做合并操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400\n",
      "1\n",
      "441\n",
      "4\n",
      "484\n",
      "9\n",
      "529\n",
      "16\n",
      "576\n",
      "25\n",
      "625\n",
      "36\n",
      "676\n",
      "49\n",
      "729\n",
      "64\n",
      "784\n",
      "81\n",
      "841\n"
     ]
    }
   ],
   "source": [
    "source1 = Stream()\n",
    "source2 = Stream()\n",
    "source1.union(source2).map(lambda x: x**2).sink(print)\n",
    "\n",
    "for i,j in zip(range(10),range(20,30)):\n",
    "    source1.emit(i)\n",
    "    source2.emit(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `combine_latest(*upstreams, **kwargs)`将不同流的最后两个元素组成tuple后合并,注意这个接口只要有一条流中有新数据传入就会触发计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 20)\n",
      "(1, 20)\n",
      "(2, 20)\n",
      "(2, 22)\n",
      "(3, 22)\n",
      "(4, 22)\n",
      "(4, 24)\n",
      "(5, 24)\n",
      "(6, 24)\n",
      "(6, 26)\n",
      "(7, 26)\n",
      "(8, 26)\n",
      "(8, 28)\n",
      "(9, 28)\n"
     ]
    }
   ],
   "source": [
    "source1 = Stream()\n",
    "source2 = Stream()\n",
    "source1.combine_latest(source2).sink(print)\n",
    "\n",
    "for i,j in zip(range(10),range(20,30)):\n",
    "    source1.emit(i)\n",
    "    if j%2==0:\n",
    "        source2.emit(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `zip(*upstreams, **kwargs)`将不同流按次序对齐并组成tuple,这个行为和python默认的zip一致,只是这个接口会丢弃无法对齐的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 20)\n",
      "(1, 22)\n",
      "(2, 24)\n",
      "(3, 26)\n",
      "(4, 28)\n"
     ]
    }
   ],
   "source": [
    "source1 = Stream()\n",
    "source2 = Stream()\n",
    "source1.zip(source2).sink(print)\n",
    "\n",
    "for i,j in zip(range(10),range(20,30)):\n",
    "    source1.emit(i)\n",
    "    if j%2==0:\n",
    "        source2.emit(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `zip_latest(lossless, *upstreams, **kwargs)`这个接口会保证所有元素都被放出来,并且最长的一条不会重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 20)\n",
      "(1, 20)\n",
      "(2, 20)\n",
      "(3, 22)\n",
      "(4, 22)\n",
      "(5, 24)\n",
      "(6, 24)\n",
      "(7, 26)\n",
      "(8, 26)\n",
      "(9, 28)\n"
     ]
    }
   ],
   "source": [
    "source1 = Stream()\n",
    "source2 = Stream()\n",
    "source1.zip_latest(source2).sink(print)\n",
    "\n",
    "for i,j in zip(range(10),range(20,30)):\n",
    "    source1.emit(i)\n",
    "    if j%2==0:\n",
    "        source2.emit(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 递归与反馈\n",
    "\n",
    "`.connect(downstream)`和`.disconnect(downstream)`可以用于将流连接起来,这常用于构造递归与反馈循环,下面的例子我们构造一个流用于遍历我们的文件系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamz import Stream\n",
    "from pathlib import Path\n",
    "source = Stream()\n",
    "\n",
    "my_path = source.unique()\n",
    "my_path.sink(print)\n",
    "\n",
    "content = my_path.map(requests.get).map(lambda x: x.content)\n",
    "links = content.map(get_list_of_links).flatten()\n",
    "links.connect(source)  # pipe new links back into pages\n",
    "\n",
    "\n",
    "source.emit('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结合dask的实时流处理\n",
    "\n",
    "最基础的流处理就是来一条处理一条的实时处理,这种模式模型最简单,但对系统的处理能力和网络io有较高要求,往往需要更多的资源.这个模式最知名的是storm框架.我们可以结合dask作为算力池直接利用集群算力来做实时流处理.\n",
    "\n",
    "\n",
    "在streamz框架下,我们使用`scatter()`接口提交计算图,使用`gather()`接收流结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同步写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment(x):\n",
    "    \"\"\" A blocking increment function\n",
    "\n",
    "    Simulates a computational function that was not designed to work\n",
    "    asynchronously\n",
    "    \"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def write(x):\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(\"localhost:8786\",processes=False) \n",
    "from streamz import Stream\n",
    "\n",
    "source = Stream()\n",
    "(source.scatter()       # scatter local elements to cluster, creating a DaskStream\n",
    "       .map(increment)  # map a function remotely\n",
    "       .buffer(5)       # allow five futures to stay on the cluster at any time\n",
    "       .gather()        # bring results back to local process\n",
    "       .sink(write))    # call write locally\n",
    "\n",
    "for x in range(10):\n",
    "    source.emit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异步写法\n",
    "\n",
    "异步写法下,`sink`接口的参数可以是一个协程函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/streaming/streaming_async.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  code/streaming/streaming_async.py\n",
    "import asyncio\n",
    "import time\n",
    "from dask.distributed import Client\n",
    "from streamz import Stream\n",
    "\n",
    "\n",
    "def increment(x):\n",
    "    \"\"\" A blocking increment function\n",
    "\n",
    "    Simulates a computational function that was not designed to work\n",
    "    asynchronously\n",
    "    \"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "async def write(x):\n",
    "    print(x)\n",
    "\n",
    "\n",
    "async def f():\n",
    "    client = await Client(\"localhost:8786\", processes=False, asynchronous=True)\n",
    "    source = Stream(asynchronous=True)\n",
    "    source.scatter().map(increment).rate_limit('500ms').gather().sink(write)\n",
    "\n",
    "    for x in range(10):\n",
    "        await source.emit(x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.get_event_loop().run_until_complete(f())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
